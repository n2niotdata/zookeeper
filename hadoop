http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/SingleCluster.html

CentOS7从零开始搭建Hadoop2.7集群.。下载软件与工具包

pscp.exe: 用于从本地到目标机器的文件传输

hadoop-2.7.3.targ.gz: Hadoop 2.7 软件包

JDK 1.8: Java 运行环境

准备四台安装好CentOS (选择基本服务器安装，最小安装会少这少那比较麻烦，反正我没有折腾了很久没有成功)的机器，且已经配置网络环境(链接方式选择桥接)。(只需要记住四台机器的IP地址，主机名后面设置)

机器1： 主机名 node， IP: 192.168.169.131

机器1： 主机名 node1， IP: 192.168.169.133

机器1： 主机名 node2， IP: 192.168.169.132

机器1： 主机名 node3， IP: 192.168.169.134

文件准备

添加用户组与用户(选择安装在root用户下可以省略这步，建议在root用户下安装，这样其他用户可以方便访问)

groupadd hadoop

useradd -d /home/hadoop -g hadoop hadoop

复制本机文件到目标机器

pscp.exe -pw 12345678 hadoop-2.7.3.tar.gz root@192.168.169.131:/usr/local

pscp.exe -pw 12345678 spark-2.0.0-bin-hadoop2.7.tgz root@192.168.169.131:/usr/local

解压并复制文件

tar -zxvf /usr/local/jdk-8u101-linux-x64.tar.gz

#重命名

mv /usr/local/jdk1.8.0_101 /usr/local/jdk1.8

tar -zxvf /usr/local/hadoop-2.7.3.tar.gz

mv /usr/local/hadoop-2.7.3 /home/hadoop/hadoop2.7

权限修改

修改夹所有者

chmod -R hadoop:hadoop /home/hadoop/hadoop2.7

修改组执行权限

chmod -R g=rwx /home/hadoop/hadoop2.7

若是以root用户安装不需要1、2步骤，root的安装是文件位置如下：Java：/usr/local/jdk1.8Hadoop：/usr/local/hadoop2.7如安装在root下，以下的遇到路径的配置做相应的修改

配置系统环境

配置系统变量

echo 'export JAVA_HOME=/usr/local/jdk1.8' >> /etc/profile

echo 'export JRE_HOME=$JAVA_HOME/jre' >> /etc/profile

echo 'export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar' >> /etc/profile

echo 'export HADOOP_HOME=${hadoopFolder}' >> /etc/profile

echo 'export PATH=$HADOOP_HOME/bin:$PATH' >> /etc/profile

source /etc/profile

配置主机域名

hostname node #当前机器名称

echo NETWORKING=yes >> /etc/sysconfig/network

echo HOSTNAME=node >> /etc/sysconfig/network #当前机器名称，避免重启主机名失效

echo '192.168.169.131 node' >> /etc/hosts

echo '192.168.169.133 node1' >> /etc/hosts

echo '192.168.169.132 node2' >> /etc/hosts

echo '192.168.169.134 node3' >> /etc/hosts

关闭防火墙

systemctl stop firewalld.service

systemctl disable firewalld.service

配置Hadoop集群

(一)、namenode配置如下：

修改配置文件----添加Java环境

sed -i 's/\${JAVA_HOME}/\/usr\/local\/jdk1.8\//' $HADOOP_HOME/etc/hadoop/hadoop-env.sh

sed -i 's/# export JAVA_HOME=\/home\/y\/libexec\/jdk1.6.0\//export JAVA_HOME=\/usr\/local\/jdk1.8\//' $HADOOP_HOME/etc/hadoop/yarn-env.sh

sed -i 's/# export JAVA_HOME=\/home\/y\/libexec\/jdk1.6.0\//export JAVA_HOME=\/usr\/local\/jdk1.8\//' $HADOOP_HOME/etc/hadoop/mapred-env.sh

配置从节点主机名

echo node1 > $HADOOP_HOME/etc/hadoop/slaves

echo node2 >> $HADOOP_HOME/etc/hadoop/slaves

echo node3 >> $HADOOP_HOME/etc/hadoop/slaves

拷贝文件并覆盖以下文件

/home/hadoop/hadoop2.7/etc/hadoop/core-site.xml

fs.defaultFS

hdfs://node:9000/

namenode settings

hadoop.tmp.dir

/home/hadoop/tmp/hadoop-${user.name}

temp folder

hadoop.proxyuser.hadoop.hosts

*

hadoop.proxyuser.hadoop.groups

/home/hadoop/hadoop2.7/etc/hadoop/hdfs-site.xml

dfs.namenode.http-address

node:50070

fetch NameNode images and edits.注意主机名称

dfs.namenode.secondary.http-address

node1:50090

fetch SecondNameNode fsimage

dfs.replication

3

replica count

dfs.namenode.name.dir

file:///home/hadoop/hadoop2.7/hdfs/name

namenode

dfs.datanode.data.dir

file:///home/hadoop/hadoop2.7/hdfs/data

DataNode

dfs.namenode.checkpoint.dir

file:///home/hadoop/hadoop2.7/hdfs/namesecondary

check point

dfs.webhdfs.enabled

true

dfs.stream-buffer-size

131072

buffer

dfs.namenode.checkpoint.period

3600

duration

/home/hadoop/hadoop2.7/etc/hadoop/mapred-site.xml

mapreduce.framework.name

yarn

mapreduce.jobtracker.address

hdfs://trucy:9001

mapreduce.jobhistory.address

node:10020

MapReduce JobHistory Server host:port, default port is 10020.

mapreduce.jobhistory.webapp.address

node:19888

MapReduce JobHistory Server Web UI host:port, default port is 19888.

/home/hadoop/hadoop2.7/etc/hadoop/yarn-site.xml

yarn.resourcemanager.hostname

node

yarn.nodemanager.aux-services

mapreduce_shuffle

yarn.nodemanager.aux-services.mapreduce.shuffle.class

org.apache.hadoop.mapred.ShuffleHandler

yarn.resourcemanager.address

node:8032

yarn.resourcemanager.scheduler.address

node:8030

yarn.resourcemanager.resource-tracker.address

node:8031

yarn.resourcemanager.admin.address

node:8033

yarn.resourcemanager.webapp.address

node:8088

(二)datanode配置

1、所有datanode都重复“配置Hadoop集群”前的操作

2、拷贝jdk和Hadoop文件到node1、node2、node3节点与node节点相应的路径下(scp 命令，不懂得百度一大堆)

3、修改slaves文件, 除了做secondnamenode节点外(这里是node1)，其他节点均清空slaves

[hadoop@node ~]$>/home/hadoop/hadoop2.7/etc/hadoop/slaves

配置无密码登录

在所有主机上创建目录并赋予权限-----root安装此步骤省略

mkdir /home/hadoop/.ssh

chomod 700 /home/hadoop/.ssh

在node主机上生成RSA文件

ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa

生成并拷贝 authorized_keys文件

cp /home/hadoop/.ssh/id_rsa.pub authorized_keys

scp /home/hadoop/.ssh/authorized_keys node1:/home/hadoop/.ssh

scp /home/hadoop/.ssh/authorized_keys node2:/home/hadoop/.ssh

scp /home/hadoop/.ssh/authorized_keys node3:/home/hadoop/.ssh

在所有主机上修改拥有者和权限-----root安装此步骤省略

chmod 600 .ssh/authorized_keys

chown -R hadoop:hadoop .ssh

修改ssh 配置文件

注释掉

# AuthorizedKeysFile .ssh/authorized_keys

重新启动ssh

service sshd restart

Note: 第一次连接仍然需要输入密码。

启动Hadoop

进入Node 主机，并切换到Hadoop账号

su hadoop

格式化 namenode

/home/hadoop/hadoop2.7/bin/hdfs namenode -format

启动 hdfs

/home/hadoop/hadoop2.7/sbin/start-dfs.sh

验证 hdfs 状态

启动 yarn

/home/hadoop/hadoop2.7/sbin/start-yarn.sh

验证 yarn 状态
默认举例

创建文件夹

/home/hadoop/hadoop2.7/bin/hadoop fs -mkdir -p /data/wordcount

/home/hadoop/hadoop2.7/bin/hadoop fs -mkdir -p /output/

上传文件

hadoop fs -put /home/hadoop/hadoop2.2/etc/hadoop/*.xml /data/wordcount/

hadoop fs -ls /data/wordcount

执行Map-Reduce

hadoop jar /home/hadoop/hadoop2.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /data/wordcount /output/wordcount

查看状态

http://192.168.169.131:8088/cluster

浏览结果

hadoop fs -cat /output/wordcount/part-r-00000 | more
